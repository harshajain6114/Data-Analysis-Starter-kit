{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#3_ML_Baseline_Template.ipynb\n",
        "\n",
        "# ==========================\n",
        "# ML Baseline Template\n",
        "# ==========================\n",
        "# WHEN TO USE:\n",
        "# After cleaning data. A \"baseline model\" gives a quick benchmark.\n",
        "# Use it before heavy feature engineering or hyperparameter tuning.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "xH8Ja6ldNzI-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load cleaned dataset\n",
        "df = pd.read_csv(\"cleaned_dataset.csv\")"
      ],
      "metadata": {
        "id": "i-ePH7uWPJ24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Setup Target + Features\n",
        "# --------------------------\n",
        "# WHEN TO USE:\n",
        "# Always separate target variable (y) from features (X).\n",
        "target_column = \"Survived\"   # change this\n",
        "X = df.drop(columns=[target_column], errors=\"ignore\")\n",
        "y = df[target_column]"
      ],
      "metadata": {
        "id": "jAoTZdgmPMj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy encode categoricals\n",
        "X = pd.get_dummies(X, drop_first=True)\n"
      ],
      "metadata": {
        "id": "oPsjW-BLPOyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split (standard = 80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "mLqDmHx-PRtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Baseline 1: Logistic Regression\n",
        "# --------------------------\n",
        "# WHEN TO USE:\n",
        "# Best starting point for binary classification.\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "gZY1L3JFPUDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Baseline 2: Random Forest\n",
        "# --------------------------\n",
        "# WHEN TO USE:\n",
        "# For non-linear datasets, handles mixed features well.\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "z3Q10X21PWgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Baseline 3: Support Vector Machine\n",
        "# --------------------------\n",
        "# WHEN TO USE:\n",
        "# Good for high-dimensional data. Sensitive to scaling.\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred = svc.predict(X_test)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"✅ Baselines tested – choose best model as benchmark.\")"
      ],
      "metadata": {
        "id": "J8dLOYILPYxl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}