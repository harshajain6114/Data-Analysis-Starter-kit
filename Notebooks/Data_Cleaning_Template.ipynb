{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 2_Data_Cleaning_Template.ipynb\n",
        "\n",
        "# ==========================\n",
        "# Data Cleaning Workflow\n",
        "# ==========================\n",
        "# WHEN TO USE:\n",
        "# After EDA, before modeling. Cleaning ensures data is consistent,\n",
        "# free of missing values/duplicates, and ready for ML.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "xH8Ja6ldNzI-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"your_dataset.csv\")\n",
        "\n",
        "print(\"Before Cleaning:\", df.shape)"
      ],
      "metadata": {
        "id": "VfLCbGRTOlbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Missing Values\n",
        "# --------------------------\n",
        "# WHEN TO USE:\n",
        "# If dataset has gaps. Filling strategy depends on variable type.\n",
        "# Median for numeric, Mode for categorical = safe baseline approach.\n",
        "missing_report = df.isnull().mean()*100\n",
        "print(\"Missing Value %:\\n\", missing_report)\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].dtype in [\"int64\", \"float64\"]:\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "    else:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])"
      ],
      "metadata": {
        "id": "m_ZvK97zOoI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Duplicates\n",
        "# --------------------------\n",
        "# WHEN TO USE:\n",
        "# Common in scraped data or combined datasets. Prevents bias.\n",
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "5Vjsh4n1OrS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Column Names\n",
        "# --------------------------\n",
        "# WHEN TO USE:\n",
        "# Standardizing names avoids errors in SQL/ML later.\n",
        "df.columns = (\n",
        "    df.columns.str.strip()\n",
        "              .str.lower()\n",
        "              .str.replace(\" \", \"_\")\n",
        "              .str.replace(\"-\", \"_\")\n",
        ")"
      ],
      "metadata": {
        "id": "TuxRP7rtOuW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Categorical Encoding\n",
        "# --------------------------\n",
        "# WHEN TO USE:\n",
        "# Needed before ML — algorithms need numbers, not text.\n",
        "for col in df.select_dtypes(include=\"object\").columns:\n",
        "    df[col] = df[col].astype(\"category\")"
      ],
      "metadata": {
        "id": "AiM3kiFfOxc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --------------------------\n",
        "# Feature Scaling (optional)\n",
        "# --------------------------\n",
        "# WHEN TO USE:\n",
        "# Only for algorithms sensitive to scale (e.g., SVM, KNN, Gradient Descent models).\n",
        "scaled_df = df.copy()\n",
        "scaler = StandardScaler()\n",
        "for col in scaled_df.select_dtypes(include=[\"float64\",\"int64\"]).columns:\n",
        "    scaled_df[col] = scaler.fit_transform(scaled_df[[col]])"
      ],
      "metadata": {
        "id": "QYIicvkBO1Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Save Outputs\n",
        "# --------------------------\n",
        "df.to_csv(\"cleaned_dataset.csv\", index=False)\n",
        "scaled_df.to_csv(\"scaled_dataset.csv\", index=False)\n",
        "\n",
        "print(\"After Cleaning:\", df.shape)\n",
        "print(\"✅ Cleaned and Scaled datasets saved\")"
      ],
      "metadata": {
        "id": "ImItiIjvO4bu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}